{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:05.438347Z",
     "start_time": "2025-02-26T16:37:02.954484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import TeacherModel, StudentModel\n",
    "from src.utils import display\n",
    "from src.preprocess import load_data\n",
    "import time"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.061605Z",
     "start_time": "2025-02-26T16:37:05.441554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the batch size for testing\n",
    "batch_size = 1\n",
    "# Load the test dataset\n",
    "_, _, test_dataloader = load_data(batch_size=batch_size, validation_split=0.2, data_dir=\"data\")"
   ],
   "id": "c3b0d6b71794c0d7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.148621Z",
     "start_time": "2025-02-26T16:37:07.096602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model and load pre-trained weights\n",
    "teacher_model = TeacherModel()\n",
    "student_model = StudentModel()\n",
    "distillate_model = StudentModel()\n",
    "student_model_pruned_1 = StudentModel()\n",
    "student_model_pruned_2 = StudentModel()\n",
    "student_model_pruned_1_fine_tuned = StudentModel()\n",
    "student_model_pruned_2_fine_tuned = StudentModel()\n",
    "# Load trained weights\n",
    "teacher_model.load_state_dict(torch.load(\"models/teacher_model.pth\", weights_only=True))\n",
    "student_model.load_state_dict(torch.load(\"models/student_model.pth\", weights_only=True))\n",
    "distillate_model.load_state_dict(torch.load(\"models/distillated_model.pth\", weights_only=True))\n",
    "student_model_pruned_1.load_state_dict(torch.load(\"models/student_model_pruned_1.pth\", weights_only=True))\n",
    "student_model_pruned_2.load_state_dict(torch.load(\"models/student_model_pruned_2.pth\", weights_only=True))\n",
    "student_model_pruned_1_fine_tuned.load_state_dict(torch.load(\"models/student_model_pruned_1_fine_tuned.pth\", weights_only=True))\n",
    "student_model_pruned_2_fine_tuned.load_state_dict(torch.load(\"models/student_model_pruned_2_fine_tuned.pth\", weights_only=True))\n",
    " # Set model to evaluation mode\n",
    "teacher_model.eval()\n",
    "student_model.eval()\n",
    "distillate_model.eval()\n",
    "student_model_pruned_1.eval()\n",
    "student_model_pruned_2.eval()\n",
    "student_model_pruned_1_fine_tuned.eval()\n",
    "student_model_pruned_2_fine_tuned.eval()\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "f15691f1821a8faa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Models Evaluation on the Test Dataset",
   "id": "eea51952c743eafb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.159067Z",
     "start_time": "2025-02-26T16:37:07.155502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize predictions for a batch of test images\n",
    "data, target = next(iter(test_dataloader))\n",
    "print(\"Target labels:\", target)"
   ],
   "id": "4655ea7ce318132f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target labels: tensor([7])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.174257Z",
     "start_time": "2025-02-26T16:37:07.171778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def measure_inference_time(model, inputs, device=\"mps\"):\n",
    "    model.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    model.eval()\n",
    "    # Warm-up (important for stable GPU measurements)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5):\n",
    "            model(inputs)\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        model(inputs)\n",
    "        end_time = time.time()\n",
    "        process_time = (end_time - start_time)\n",
    "    return process_time"
   ],
   "id": "38e378c6ec2f9a5a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.270149Z",
     "start_time": "2025-02-26T16:37:07.185320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(teacher_model, data)\n",
    "print(f\"Teacher model inference time: {process_time* 1e6:.6f} useconds\")"
   ],
   "id": "116a217bff5bb263",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model inference time: 512.123108 useconds\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.358059Z",
     "start_time": "2025-02-26T16:37:07.336705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(student_model, data)\n",
    "print(f\"Student model inference time: {process_time* 1e6:.6f} useconds\")"
   ],
   "id": "6dfe465941686c1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model inference time: 177.860260 useconds\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.434728Z",
     "start_time": "2025-02-26T16:37:07.427956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(distillate_model, data)\n",
    "print(f\"Distillated model inference time: {process_time* 1e6:.6f} useconds \")"
   ],
   "id": "1ff52ba72a260d86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillated model inference time: 257.968903 useconds \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.486825Z",
     "start_time": "2025-02-26T16:37:07.480999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(student_model_pruned_1, data)\n",
    "print(f\"Student model structured pruning inference time: {process_time * 1e6:.6f} useconds\")"
   ],
   "id": "72e893022d3c946",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model structured pruning inference time: 200.033188 useconds\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.503167Z",
     "start_time": "2025-02-26T16:37:07.497355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(student_model_pruned_2, data)\n",
    "print(f\"Student model unstructured pruning inference time: {process_time * 1e6:.6f} useconds\")"
   ],
   "id": "b69b58a164543c7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model unstructured pruning inference time: 174.999237 useconds\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.525970Z",
     "start_time": "2025-02-26T16:37:07.520679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(student_model_pruned_1_fine_tuned, data)\n",
    "print(f\"Student model structured pruning and fine-tuned inference time: {process_time * 1e6 :.6f} useconds\")"
   ],
   "id": "b82bde971fa83ba9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model structured pruning and fine-tuned inference time: 174.045563 useconds\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:37:07.540606Z",
     "start_time": "2025-02-26T16:37:07.534994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_time = measure_inference_time(student_model_pruned_2_fine_tuned, data)\n",
    "print(f\"Student model unstructured pruning and fine-tuned inference time: {process_time * 1e6:.6f} useconds\")"
   ],
   "id": "2a1d704c29efa679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model unstructured pruning and fine-tuned inference time: 174.760818 useconds\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
